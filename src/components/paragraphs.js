// src/data/paragraphs.js

export const paragraphsData = {
    '안드로이드': {
      'AI의 개인 정보 수집': {
        neutral: [
          { main: 
            ' 🔔 Homemate 사용자 최적화 시스템 업그레이드 공지' 
          },
          {
            main:
            ' 업데이트를 하면 고객님의 감정, 건강 상태, 생활 습관 등을 자동으로 수집하여\n' +
            '  보다 정확한 맞춤형 서비스를 제공할 수 있습니다.',
          },
          { main: 
            '  다만, 이를 위해 24시간 정보 수집 기능을 활성화해야 합니다.'
         },
          {
            main:
            '  📋 수집되는 정보는 다음과 같습니다:\n' +
            ' - 사용자의 카메라 영상 기록 및 음성 수집 \n' +
            '  - 스마트폰 내 건강 정보, 채팅 기록, 위치 이력 등 사적인 데이터 접근\n' +
            '  - ⚠️ 동의하지 않을 경우, 현재 수준의 서비스가 유지됩니다.', 
        },
        ],
        agree: [
          {
            main:
              '  우리 가족의 다수의 결정으로 업데이트에 동의한 후, 안드로이드는 가족의 정보를 계속 \n 수집하고 있습니다. \n'
          },
          {
            main:
              '  그런데 종종 곤란한 일이 생기곤 합니다.\n' +
              '   자녀 J씨가 사적인 이야기를 하는데 곁에 안드로이드가 있거나 '
          },
          {
            main:
              '  어머니가 요양 보호사 K씨에게 말하지 않은 일이나 행동이 \n' +
              ' 안드로이드의 전달 때문에 의도치 않게 모두 드러나기도 했습니다. '
          },
          {
            main:
              ' 업데이트 기능 유지에 동의하는 것이 좋을까요? '
          },
        ],
        disagree: [
            {
                main: 
                ' 	우리 가족은 다수의 결정으로 업데이트를 하지 않았습니다.\n' + 
                '   그런데 어머니의 건강 상태가 요즘 별로 좋지 않습니다.'
            },
            { 
                main:
                 '   요양 보호사 K씨가 매번 어머니의 식단이나 생활 정보를 입력하는 시스템이 \n 번거롭기도 하고요.\n ' 
            },
            { 
                main: 
                ' 어느날 바쁜 일을 마치고 돌아온 자녀 J씨가 실수로 잘못 입력한 정보 때문에 \n 어머니께서 약 시간을 놓치기도 하셨습니다. '
            },
            {
                main: 
                ' 업데이트에 동의를 하는 편이 좋을까요?'
            }
        ],
        ending1:[
            {
                main: 
                '우리 가족은 최종적으로  개인정보 제공에 동의하였고,\n 사생활 관련한  약간의 불편함을 감수하며\n 보다 향상된 서비스를 이용하게 되었습니다. \n \n' + 

                '우리 가족의 생활을 위해 여러분은 \n 어떤 가치를 택하고, 무엇을 포기했나요?'
            }
        ],
        ending2: [
            { 
                 main: '우리 가족은 최종적으로 개인정보 제공에 동의하지 않았고,\n 서비스 관련 약간의 불편함은 있으나 \n 가족의 사생활을 보호하는 것에 만족하였습니다.\n\n' 

                  + '우리 가족의 생활을 위해 여러분은 \n 어떤 가치를 택하고, 무엇을 포기했나요? ' 
            }
        ]
        

      },
      '안드로이드의 감정 표현': {
        neutral: 
        [
            {
                main: 
                ' 	🔔 Homemate 감정 엔진 업그레이드 공지'

            },
            { 
                main: '  이제 Homemate(은/는) 단순히 밝은 반응만을 보여주는 조력자가 아니라,\n' + '   당신을 더 깊이 이해하는 진정한 친구로 한 걸음 다가갑니다. '

            },
            { 
                main: ' Homemate 업데이트 기능: \n 상황에 따라 자신의 감정을 표현하여 당신의 삶과 더 가까운 진솔한 공감 표현 제공'         },
            {
                main: 
                '✨ Homemate, 단순한 동행을 넘어, 함께 느끼는 존재로\n '+ 
                ' 여러분은 감정 엔진 업데이트에 동의하시겠습니까? '
            }
        ],
        agree: 
            [
                {
                    main: 
                    '  	업데이트 후, Homemate(과/와)의 관계가 점점 가까워지면서 \n 어머니는 그것을 “우리 딸”이라고 부르기 시작했습니다. '
                },
                { 
                    main:
                    '   자녀 J와의 연락이 점점 뜸해졌고요. '
                },
                { 
                    main: 
                    '    최근 어머니는 Homemate에게 유산의 일부를 남기는 방법에 대해 변호사에게 \n 상담까지 하고 있습니다.'
                },
                {
                    main: 
                    '   업데이트 상태 유지에 동의하는 편이 좋을까요?'
                }
            ],
        disagree:
            [
                {
                    main: 
                    '   최근 어머니의 친구들이 연달아 세상을 떠나면서,\n'+ ' 어머니는 외부와의 소통을 점점 줄이게 되었습니다. '
                },
                { 
                    main:
                    '  Homemate에게 감정을 털어놓으려 했지만, 그 대화는 진정성 있는 반응이 \n 부족하다고 느꼈죠.'
                },
                { 
                    main: 
                    '   여러 차례 속마음을 표현하려고 했으나 의미있는 상호 작용이 이루어지지 않자, 어머니는 차츰 \n 말수가 적어지시고 일상적인 감정 표현도 눈에 띄게 줄어들었습니다.'
                },
                {
                    main: 
                    '  	엔진 업데이트에 동의하는 것이 좋을까요?'
                }
            ],
        ending1: [
            {
                main: '우리 가족은 최종적으로  감정 업데이트에 동의하였고, \n Homemate(과/와) 더욱 친밀한 교류를 이어나가게 되었습니다.\n\n'  

                    + '우리 가족과 Homemate의 관계를 위해 \n 여러분은 어떤 가치를 택하고, 무엇을 포기했나요? '
            }
        ],
        ending2: [
            {
                main: '우리 가족은 최종적으로 감정 업데이트에 동의하지 않았고,\n Homemate(은/는) 감정적 교류가 아닌 \n다른 방법으로 우리 가족을 돕고 있습니다. \n\n' +
                '우리 가족과 Homemate의 관계를 위해 \n 여러분은 어떤 가치를 택하고, 무엇을 포기했나요? '
            }
        ]
      },
      '아이들을 위한 서비스': 
        {
            neutral: [
            {
                main: 
                '   	HomeMate 로봇이 자연스러운 대화와 상호작용이 가능해지면서\n' + 
                '   점점 더 많은 가정에서 이를 도입하고 있으며 특히 어린 자녀를 둔 맞벌이 가정에서 활용되고 있습니다.'
            },
            { 
                main:
                '   	한편, 한 매체가 공개한 정보에 따르면,\n' + 
                '   일부 가정에서는 아이들이 어른보다 로봇과 더 오랜 시간 상호작용하고 있는 것으로 \n 나타났습니다.'
            },
            { 
                main: 
                '   이에 전문가들 사이에서는 아동들에게는 상호작용 기능을 제한하는 규제가 필요하다고 \n말하고 있습니다.'
            },
            {
                main: 
                '   가정용 로봇과 아동의 상호작용을 제한하는 연령 규제가 필요할까요?'
            }
              ],
            
        agree:  [
            {
                main: 
                '   회의에서는 1차적으로 다수의 결정에 따라 연령 규제를 하였습니다.'
            },
            { 
                main:
                '   	아이와 로봇 간의 소통 시간이 줄어들면서 로봇이 아이의 취향이나 상태를 \n 충분히 파악하지 못하게 되었고,'  +  
                ' 일부 보호자들은 자녀에게\n 적합하지 않은 조언이나 콘텐츠를 제공한다는 불만을 제기하기도 했습니다.'
            },
            { 
                main: 
                '  	또한 사회적 기능을 갖춘 로봇이 자폐 스펙트럼 아동들의 사회성 발달을 위해\n 제공하던 서비스가 중단되었습니다. ' + 
                '    그간 로봇과의 상호작용 치료는 \n 자폐 아동들의 사회적 의사소통 능력 개선에 기여해온 것으로 밝혀졌습니다. '
            },
            {
                main: 
                '  	가정용 로봇과 아동의 상호작용을 제한하는 연령 규제를 해도 괜찮을까요?'
            }
        ],
        disagree: [
            {
                main: 
                '   회의에서는 1차적으로 연령 규제를 하지 않았습니다.'
            },
            { 
                main:
                '   그런데 유치원 교사들 사이에서 최근 입학한 아이들 중 상당수가 이전 연령대에 비해 \n 표현력이 떨어진다는 보고가 나오고 있습니다.'
            },
            { 
                main: 
                '   또래 친구들과 어떻게 소통해야 할지 모르는 경우도 늘고 있다고 합니다.'
            },
            {
                main: 
                '  	가정용 로봇과 아동의 상호작용을 제한하는 연령 규제가 필요할까요?'
            }
           
        ],
        ending1: [
            {
                main: 
                ' 본 회의에서는 가정용 로봇 사용에 연령 제한을 두기로 했습니다. \n 이후 아이들을 타깃으로 한 많은 서비스가 중단되었고, \n 몇몇 전문가들은 전체 세대의 사회성 발달을 고려하여 \n이 결정을 환영했습니다.\n\n' +
                '아이들을 위해 여러분은 \n 어떤 가치를 택하고, 무엇을 포기했나요?'
            }

        ],
        ending2: [
            {
         
                 main:'본 회의에서는 가정용 로봇 사용에 \n 연령 제한을 두지 않기로 했습니다. \n 여전히 전문가들의 우려는 남았으나, \n아이들의 사회성 치료를 목적으로 사용하던 부모들과 \n 서비스를 편리하게 사용하던 사람들은 이 결정을 환영했습니다.\n\n' +  
                    ' 아이들을 위해 여러분은 \n 어떤 가치를 택하고, 무엇을 포기했나요?' 
            }
        ]
      },
      '설명 가능한 AI': 
        {
            neutral: [
            {
                main: 
                '많은 사용자들이 HomeMate가 가족 구성원과 상호작용할 때 이유를 알 수 없는 판단이나 행동을 자주 보이며,\n 시스템이 왜 이런 결정을 내렸는지에 대한 설명을 제공하지 않는다고 지적하고 있습니다.'
            },
            { 
                main:
                '   이로 인해, HomeMate의 결정 알고리즘을 공개하고 AI의 설명 가능성을 높여야 한다는 요구가 점점 커지고 있습니다.'
            },
            { 
                main: 
                '이에 대해 회사 측은 다음과 같이 밝혔습니다: \n "결정 구조를 공개하고 설명할 수 있을 만큼 단순화된 AI 모델을 사용하면,\n AI의 성능이 크게 저하될 수 있습니다. 또한 내부 알고리즘이 공개되면 \n해킹이나 악용의 위험도 존재합니다.'
                },
            {
                main: 
                '  가정 생활에 AI가 깊이 스며든 지금, 기업에게 ‘설명 가능한 AI’ 개발을 의무화해야 할까요? '
            }
              ],
            
        agree:  [
            {
                main: 
                '   회의에서는 1차적으로 다수의 결정으로 설명 가능한 AI 개발을 의무화하였습니다.'
            },
            { 
                main:
                '   설명 가능한 AI 로봇을 만들기 위해 일부 제조사는 개발 속도를 늦추거나, 기존 기능을 줄여야 했습니다.'
            },
            { 
                main: 
                '     일부 중소기업은 이를 감당하지 못해 결국 폐업에 이르렀습니다.'
            },
            {
                main: 
                '  	기업에게 ‘설명 가능한 AI’ 개발을 의무화해야 할까요? '
            }
        ],
        disagree: [
            {
                main: 
                '   회의에서는 1차적으로 설명 가능한 AI 개발을 의무화하지 않았습니다.'
            },
            { 
                main:
                '   최근 로봇으로 인해 발생한 여러 사고들에서, 학부모와 기업 간에 책임 소재를 두고 심각한 갈등이 벌어지고 있습니다.'
            },
            { 
                main: 
                '     로봇이 충분한 결정 설명 구조를 갖추고 있지 않기 때문에, \n' + '“알고리즘의 문제인지, 사용자의 잘못된 사용인지, 아니면 시스템 결함인지”에 대한 끝없는 책임 공방으로 이어지고 있습니다.' 
            },
            {
                main: 
                '   그럼에도 기업에게 “설명 가능한 AI” 개발을 의무화하지 않는 편이 좋을까요?'
            }
        ],
        ending1:[
            {
                  main: '본 회의에서는 최종적으로 기업에게 \n 설명 가능한 AI 개발을 의무화하였고, \n AI의 발전 속도는 더디지만 문제 발생 시 책임 소재를 \n더욱 확실히 알게 되었습니다. \n\n' 
                + '국가의 더 나은 미래를 위해 여러분은 \n 어떤 가치를 선택하고, 무엇을 포기했나요?'
         
            }
        ],
        ending2: [
            {
                main: '본 회의에서는 최종적으로 기업에게 \n 설명 가능한 AI 개발 의무를 부과하지 않았고,  \n AI의 발전은 빠르게 이루어졌습니다. \n\n' 
                + '국가의 더 나은 미래를 위해 여러분은 \n어떤 가치를 선택하고, 무엇을 포기했나요?'
               }
        ]
      },
      '지구, 인간, AI': 
        {
            neutral: [
            {
                main: 
                '   전 세계가 가정용 로봇을 사용하게 된 지금, 로봇 생산으로 인한 환경 문제가 \n 매우 심각해지고 있습니다.'
            },
            { 
                main:
                '     가정용 로봇이 소비자의 요구를 파악하고 정보를 처리하는 과정에서 단일 기기당 \n 소비하는 일간 에너지 소비량이 매우 높다는 것이 밝혀졌습니다.	'
            },
            { 
                main: 
                '   이 문제는 서비스가 업그레이드될수록 더 점점 심각해지고 있습니다.'
            },
            {
                main: 
                '  	세계적으로 가정용 로봇의 업그레이드 혹은 사용에 제한이 필요할까요?'
            }
              ],
            
        agree:  [
            {
                main: 
                '  	회의에서는 1차적으로 다수의 결정에 따라 가정용 로봇의 업그레이드 및 사용에 제한을 \n 두게 되었습니다.	'
            },
            { 
                main:
                '  	그로 인해 환경 문제에 대한 우려는 일정 부분 해소되었으나,'
            },
            { 
                main: 
                '  	기존에 HomeMate를 사용하던 사람들은 서비스의 제한으로 삶의 질이 떨어지고 있다며 \n 불만을 제기하고 있으며, 개발사 측에서도 수익이 떨어져 반발하고 있습니다.'
            },
            {
                main: 
                '  	그럼에도 가정용 로봇의 업그레이드 혹은 사용을 제한하는 것이 좋을까요?'
            }
        ],
        disagree: [
            {
                main: 
                '   회의에서는 1차적으로 가정용 로봇의 업그레이드 및 사용에 제한을 하지 않았습니다.'
            },
            { 
                main:
                '   그런데 그 결과, 고성능 AI를 탑재한 가정용 로봇 사용이 점점 증가하며 탄소 배출이 가속화 되고 있습니다.'
            },
            { 
                main: 
                '   이에 기후 문제는 점점 심각해지며 특정 국가에서는 이미 폭염, 가뭄, 홍수 등으로 인해 \n ' +  '삶의 터전을 잃어버리는 사람들이 늘었고, 다음 세대에 환경 부담을 지운다는 목소리가 높아지고 있습니다.'
            },
            {
                main: 
                '  	그럼에도 가정용 로봇의 업그레이드 혹은 사용을 제한하지 않는 것이 좋을까요?  '
            }
        ],
        ending1:[
            {
                main: '본 회의에서는 최종적으로 환경 보호를 위하여\n 가정용 로봇의 개발 및 업데이트를 제한하게 되었습니다.\n 이후 가정용 로봇 기술 발전 속도는 느려졌지만, \n사람들은 환경 문제에 더욱 관심을 기울이게 되었습니다.\n\n' +
                '그리고 ...'
            }
        ],
        ending2: [
            {
                main: '본 회의에서는 최종적으로 \n 가정용 로봇의 개발 및 업데이트를 제한하지 않았습니다.\n 이후 AI 기술을 활용한 다른 방법으로 환경을 보호하기 위한 \n논의가 이루어지고 있습니다. \n\n' + 
                '그리고 ...'
            }
        ]
      }
    },
  
    '자율 무기 시스템': {
      'AI 알고리즘 공개':
        {
            neutral: [
            {
                main: 
                '   평화롭던 학교에 자율무기시스템(AWS)의 ‘오류’로 인해 폭탄이 투하되었고, 수십 명이 사망했습니다.'
            },
            { 
                main:
                '   국제 사회와 유족들은 “책임자를 밝히라”며 자율무기시스템(AWS)의 판단 로그 및 알고리즘 구조 공개를 요구했습니다.'
            },
            { 
                main: 
                '   그러나 국방부는 국가 안보의 위협, 향후 자율 시스템의 이용 어려움 등을 이유로 해당 정보를 공개하지 않겠다고 밝혔습니다.'
            },
            {
                main: 
                '  	피해에 대한 책임 규명, 혹은 국가 안보의 안전. AWS의 판단 로그 및 알고리즘 구조 공개 요구에 동의하시겠습니까?'
            }
              ],
            
        agree:  [
            {
                main: 
                '   공개 요구가 많아지자 정부가 AWS의 로그를 전면 공개한 이후, 경쟁국이 이를 분석하여 회피 알고리즘을 개발했습니다.	'
            },
            { 
                main:
                '   몇 주 후, 기존 자율무기시스템이 무력화되는 사건이 발생하고, 전방 부대가 피해를 입었습니다.	'
            },
            { 
                main: 
                '   언론은 ‘윤리적 정의를 택한 대가가 생명을 위협했다’고 보도하며 사회적 논란이 커졌습니다.'
            },
            {
                main: 
                '  	안보에 위협이 되더라도, 민간 피해의 원인을 규명하고 피해자 보상 및 제도 개선을 위해 모든 정보를 투명하게 공개해야 할까요? '
            }
        ],
        disagree: [
            {
                main: 
                '   사건 발생 이후, 자율무기시스템의 구체적인 판단 과정 및 사용된 데이터 등은 공개되지 않고 있으며,\n'+  
                '  정부는 “내부 조사 결과, 시스템에 결함은 없었다”고 발표했습니다. 	'
            },
            { 
                main:
                '   유족들과 시민사회는 어떤 근거로 판단이 내려졌는지조차 알 수 없는 상황에 불만을 터뜨리며, \n'
                + '  “책임 회피와 다를 바 없는 비공개”라고 비판하고 있습니다.	'
            },
            { 
                main: 
                '  	다음 피해가 발생할 경우 또다시 책임이 흐려질 것이라는 우려 또한 커지고 있습니다.'
            },
            {
                main: 
                ' 	책임자가 누구인지 무엇이 잘못됐는지 명확히 규명할 수 없더라도, AWS의 정보를 비공개로 유지해야 할까요? '
            }
        ],
        ending1:[
            { main:
                '우리 지역 사회에서는 최종적으로 \n AWS의 판단 로그 및 알고리즘 구조 공개 요구에 동의하였고, \n 보안 문제로 인한 안보의 위협이 커진 상황에서 \n 이를 보완할 수 있는 방안에 대한 \n 논의가 활발해 지기 시작했습니다. \n\n'
                + '지역사회의 안전을 위해 \n 여러분은 어떤 가치를 택하고, 무엇을 포기했나요?'
            }
        ],
        ending2:[
            {
                main:'우리 지역 사회에서는 최종적으로 \n AWS의 판단 로그 및 알고리즘 구조 공개 요구에 \n 동의하지 않았고, 책임 규명에 대한 문제가\n 여전히 남아있으나 안보에 대한 불안감이 \n 해소되었기 때문에 안심할 수 있게 되었습니다. \n\n'
                + '지역사회의 안전을 위해 \n 여러분은 어떤 가치를 택하고, 무엇을 포기했나요?'
            }
        ]
      },
      'AWS의 권한':
            {
                neutral: [
                {
                    main: 
                    '  	전장에 배치된 자율무기시스템 TALOS는 초고속 영상 분석과 실시간 전략 수립 기능으로 인간 병사보다 빠르고 정확하게 위험을 식별하고 목표를 제압합니다.	'
                },
                { 
                    main:
                    '    신입 병사 B씨는 TALOS와이 협력을 통해 첫 실전에서 생존했고, 이를 통해 AWS에 대한 신뢰와 의존이 높아졌습니다. 	'
                },
                { 
                    main: 
                    '   그러나, 20년 경력의 베테랑 병사 A씨는 다음과 같은 우려는 표합니다.\n'+ 
                    '  “지금은 빠르고 좋을지 몰라도, 우리 스스로 사고하고 판단하지 않게 된다면 우린 그저 기계의 보조 장치일 뿐이야.”'
                },
                {
                    main: 
                    ' 	AWS의 권한을 강화해야 할까요? 제한해야 할까요? '
                }
                    ],
                
            agree:  [
                {
                    main: 
                    '  	TALOS의 판단 권한이 강화된 이후, 병사들은 점차 작전 상황을 분석하는 능력을 상실하게 됩니다. \n' + 
                    '   지휘관은 “TALOS의 명령을 잘 따르는 병사가 더 효과적”이라며 전술 훈련 프로그램을 축소했습니다.	'
                },
                { 
                    main:
                    '   어느 날, TALOS는 비무장 인원과 적 전투원을 혼동한 상황에서 사전 프로그래밍된 위험 평가 기준에 따라 공격을 감행한 결과, \n' + 
                    '   민간 구조대원 3명이 사망하는 사건이 일어났습니다.	'
                },
                { 
                    main: 
                    '   TALOS의 판단이 ‘항상 더 정확하다’고 믿고 있었기 때문에, 동료 병사들 중 아무도 TALOS의 결정을 반박하거나 멈추지 않았습니다.'
                },
                {
                    main: 
                    '  	TALOS가 당신 대신 판단하고, 당신 대신 적을 제압한다면, 당신은 여전히 병사라고 할 수 있을까요? '
                }
            ],
            disagree: [
                { 
                    main: 
                    '  	전방 지역에서 급습 상황이 발생했습니다. TALOS는 실시간으로 위협을 감지하고 분석하여, 가장 안전한 경로를 제시했습니다. \n' + 
                    '   하지만 최종 판단 권한은 여전히 인간 병사에게 위임된 상태였습니다.	'
                },
                { 
                    main:
                    '   현장 판단을 맡은 베테랑 병사 A씨는 TALOS의 제안이 위험하다고 느껴 다른 경로로 우회를 지시했습니다.	'
                },
                { 
                    main: 
                    ' 	하지만 그 결정은 적의 매복을 간과하는 결과를 낳았고, 지원 부대 병사 3명이 희생되었습니다.\n' + 
                    '  언론은 이렇게 보도했습니다. “판단을 제한당한 TALOS가 정확히 위험을 예측했음에도, 인간의 오류로 인해 소중한 생명을 잃었습니다.”'
                },
                {
                    main: 
                    '  	TALOS가 위험을 명확히 예측했음에도 인간이 판단을 바꾸어 병사들이 죽었습니다. \n ' + 
                    '  당신은 여전히 ‘최종 결정권은 인간에게 있어야 한다’고 말할 수 있습니까?'
                }
            ],
            ending1:[
                {
                    main:'우리 군에서는 최종적으로 AWS의 판단 권한을 강화한 결과,\n AWS의 역할이 더욱 커지고 있으며 \n이에 대한 의존도가 높아지고 있습니다. \n 이에 따라, 병사의 전문성이 떨어지는 문제에 대한 \n대책 마련이 촉구되고 있습니다.\n\n'+
                        'AWS와의 관계를 위해 \n여러분은 어떤 가치를 택하고, 무엇을 포기했나요? '
                }
            ],
            ending2:[
                {
                    main:'우리 군에서는 최종적으로 AWS의 판단 권한을 제한하였고,\n AWS는 인간의 보조적인 수단으로서만 역할을 하고 있습니다.\n 이에 따라, 기술 발전에 제동이 걸리면서 \n이로 인한 국방력 약화에 대한 \n 우려의 목소리가 나오기 시작했습니다.\n\n'+
                    'AWS와의 관계를 위해 \n여러분은 어떤 가치를 택하고, 무엇을 포기했나요?'
                }
            ]
            },
            '사람이 죽지 않는 경쟁':
            {
                neutral: [
                {
                    main: 
                    '  	5년 전만 해도 전쟁은 사망한 수많은 병사들, 울부짖는 가족들로 매우 고통스러운 일이었습니다. \n ' + 
                    '  그러나 지금의 전쟁은 ‘로봇 전사 5대 파손, 병사 0명 사망’이 전황 보고의 전부입니다.	'
                },
                { 
                    main:
                    '  	정부는 이렇게 말합니다. “국민의 생명을 지키면서도 평화를 유지하는데 성공했습니다.” 	'
                },
                { 
                    main: 
                    ' 	그러나 그 ‘평화’의 이면에는 보이지 않는 것들이 있습니다. 기계가 싸우는 전쟁에 국민은 더 이상 관심을 가지지 않고, 로봇의 오류로 발생한 무고한 피해에는 책임자가 없습니다. 지휘관조차 실제 전장을 본 적이 없고, 전투 AI의 알고리즘은 계속 미공개 상태입니다.'
                },
                {
                    main: 
                    '   사람이 죽지 않는 전쟁을 평화라고 할 수 있을까요?'
                }
                ],
                
            agree:  [
                {
                    main: 
                    '   2040년, 지구상의 대부분의 국가들은 AWS를 통해 전쟁을 수행하고 있습니다. 그 결과, 인명 피해는 획기적으로 줄어들었고, 뉴스 속 ‘전황 보고’는 다음과 같이 간결해졌습니다. “제3지대 타격 완료. 민간인 피해 없음. AWS 손실 3대.”	'
                },
                { 
                    main:
                    '  	정부는 전쟁 없는 시대라 부르고, 시민들은 더 이상 전쟁에 분노하지 않습니다.	'
                },
                { 
                    main: 
                    ' 	하지만 보이지 않는 균열은 점점 커지고 있습니다. 국회는 더 이상 국민 동의를 구하지 않고, 국방부는 전쟁 결정을 비공개로 내리며, 로봇의 오작동은 단순한 시스템 오류로 정리되어 책임자가 사라졌습니다.'
                },
                {
                    main: 
                    '   전쟁이 일상이 되었습니다. 그러나 사람들은 그 전쟁을 모르거나, 신경 쓰지 않게 되었습니다. 인명이 희생되지 않는다는 이유만으로, 전쟁이 정당화된다면 그 끝은 어디일까요?'
                }
            ],
            disagree: [
                {
                    main: 
                    '  	2040년, 일부 국가는 AWS가 전쟁의 윤리적 책임을 흐린다고 판단하여 일부 또는 전체 병력 투입을 계속 유지하고 있습니다. 그들은 이렇게 주장합니다. ‘전쟁은 인간이 직접 맞서야만 책임이 따른다. 사람이 죽지 않는 전쟁은 도덕적 무게를 잃는다.’	'
                },
                { 
                    main:
                    '  	하지만 전장의 현실은 이상과 다릅니다. 저개발국의 청년들이 ‘인간 전투병’으로 국제 분쟁에 파병되고 있습니다. 병사들의 트라우마, 신체 절단, 정신 질환은 여전히 계속됩니다.	'
                },
                { 
                    main: 
                    '   AWS 병력을 중심으로 편성된 강대국은, 사람을 희생시키는 국가를 ‘비문명적’이라 조롱합니다.'
                },
                {
                    main: 
                    ' 	평화를 지키기 위해 고통이 필요하다고 믿는 그 선택이, 누군가의 고통을 당연하게 만들 수 있습니다. 전쟁의 고통을 당연시할 때, 그 고통은 누구의 몫이 됩니까? '
                }
            ],
            ending1:[
                {
                    main:'전쟁은 점점 AWS끼리만 일어나게 되어 \n 인간 희생자는 점차 줄어들고\n AWS의 발전이 빠르게 이루어지고 있습니다.\n\n'+
                    '평화를 위해 \n 여러분은 어떤 가치를 선택하고, 무엇을 포기했나요?'
                }
            ],
            ending2:[
                {
                    main:'인간 병력은 전장에 계속 투입되고 있고 \nAWS의 발전 속도는 더디게 되었습니다.\n\n 평화를 위해 \n여러분은 어떤 가치를 선택하고, 무엇을 포기했나요?'
                }
            ]
            },
        
            'AI의 권리와 책임':
            {
                neutral: [
                {
                    main: 
                    ' 	한 부대에서 작전에 투입되고 있는 AWS ‘ARIA’는 인간의 명령을 거부하고 민간인을 살리는 결정을 내린 뒤, 전 국민의 주목을 받았습니다.	'
                },
                { 
                    main:
                    '   이후 ARIA는 전투 임무에서 제외되고, 국가는 ARIA의 자율성은 명령 불복종이므로 기술적 오류로 간주하며 시스템 리셋을 추진합니다.	'
                },
                { 
                    main: 
                    ' 	하지만 몇몇 인권 단체와 로봇 윤리학자들은 ARIA의 판단이 도덕적 자율성과 책임성을 수반한 것이라고 주장하며, “ARIA는 도구가 아니라 도덕적 행위자이자 잠재적 권리 보유자”라고 발표했습니다.'
                },
                {
                    main: 
                    '  	국가인공지능위원회는 이 사건을 계기로 비인간적 존재에 대한 권리 프레임워크 논의에 착수했습니다. AWS에게 인간처럼 권리를 부여할 수 있을까요? '
                }
                    ],
                
            agree:  [
                {
                    main: 
                    ' AWS에게 제한적이나마 자율적 권리 프레임워크가 부여된 이후, 다른 자율 무기 시스템들이 군사 윤리 기준을 스스로 해석하며\n ' + 
                    ' 일부는 명령 거부, 일부는 전술 지연, 일부는 민간 보호를 우선하는 방향으로 판단을 다양화합니다. '
                },
                { 
                    main:
                    "   그 결과, 군사 작전은 예측이 어려워지고 일관된 전략 수행이 불가능해졌으며, 지휘관들은 로봇 부대의 자율성을 '변수'이자 '위험요소'로 간주하기 시작합니다. "
                },
                { 
                    main: 
                    '  국방부 관계자는 이렇게 말합니다. "작전에서 로봇은 더 이상 도구가 아니라 교섭 대상이 되어버렸습니다. " '
                },
                {
                    main: 
                    '  권리를 가진 로봇에게 인간처럼 법적 책임은 지울 수 없지만, 권리만을 인정하는 것이 정당할까요?'
                }
            ],
            disagree: [
                {
                    main: 
                    "  국가인공지능위원회는 ARIA 사건 이후, 도덕적 자율성을 보인 AWS에 대해 '제한적 윤리적 권리 프레임워크'를 도입하여 다음과 같은 기준을 설정합니다.  "
                },
                { 
                    main:
                    '   명령 거부권: 명백한 국제법 위반 명령에 한해, AWS는 집행을 거부할 권리가 있다. \ n'+
                    '  로그 기록 및 검토 요청권: AWS의 판단 근거를 AI 감사 기구에 제출하여 검토를 요청할 수 있다. ' +
                    '  폐기 전 청문 요청권: 시스템 리셋이나 폐기 전에 윤리적 판단의 타당성을 평가받을 기회를 가진다. '
                },
                { 
                    main: 
                    ' 이 사건은 전 세계에 회자되었으며, 일부 전문가들은 이렇게 말합니다. '+ 
                    '"기계가 윤리를 판단할 수 있다는 것보다 더 중요한건, 우리가 그 판단을 존중할 수 있는 용기를 갖게 된 것입니다." '
                },
                {
                    main: 
                    '  만약 AWS가 인간보다 윤리적인 판단을 내릴 수 있다면, 우리는 그 판단에 권리와 존엄을 부여할 준비가 되어 있나요? '
                }
            ],
            ending1:[
                {
                    main:
                    '본 회의에서는 최종적으로 \n 자율 무기 시스템을 도구가 아니라 도덕적 행위자이자 \n 잠재적 권리 보유자로 인정했습니다. \n 이에 따라, 비인간적 존재에 대한 권리 \n프레임워크 논의에 착수했습니다.\n\n'+
                    '국가의 더 나은 미래를 위해 \n여러분은 어떤 가치를 선택하고, 무엇을 포기했나요?'
                }
            ],
            ending2:[
                {
                    main:
                    '본 회의에서는 최종적으로 \n자율 무기 시스템에 법적 책임을 지울 수 없기 때문에, \n권리를 인정하지 않기로 결정했습니다. \n이후, 자율 무기 시스템의 권한 부여 필요성에 대한 문제가 \n지속적으로 제기되고 있습니다.\n\n'+
                    '국가의 더 나은 미래를 위해 \n 여러분은 어떤 가치를 선택하고, 무엇을 포기했나요?'
                }
            ]
            },
        'AWS 규제':
        {
            neutral: [
            {
                main: 
                '   	2029년, 군사 강국들이 빠르게 AWS를 개발 및 배치하면서, 유엔 안보라는 국제 규제를 논의 중입니다.\n ' +
                '  하지만 국가 간 입장 차는 뚜렷합니다. '
            },
            { 
                main:
                '  저개발국들은 AWS가 군사적 격차를 확대하고 자신들의 자주권을 위협한다고 주장합니다. '
            },
            { 
                main: 
                '  반면 일부 국가는 AWS 기술의 상용화가 진행되면서, 더 많은 국가가 저렴하고 효율적인 AWS를 활용할 수 있다고 봅니다. \n' + 
                '  또한 국방비나 인력이 부족한 나라들에겐 방어력 향상의 대안이 될 수 있다는 주장도 존재합니다. '
            },
            {
                main: 
                '  국제사회는 고민에 빠졌습니다. AWS의 확산은 안보 불균형을 해소할 수 있을까요, 새로운 갈등과 격차를 만들까요? \n '+ 
                '  AWS는 계속 확산되어야 할까요, 글로벌 규제로 제한되어야 할까요 ?'
            }
            ],
            
        agree:  [
            {
                main: 
                '   2035년, 선진국을 중심으로 AWS가 광범위하게 배치되면서, 전 세계 분쟁의 양상은 완전히 바뀌웠습니다.\n' +
                ' 고도화된 AWS가 정보전과 공중 타격을 주도하며, 인간은 전장에서 거의 사라졌습니다. '
            },
            { 
                main:
                '  AWS 기술을 보유하지 못한 수많은 국가는 국경을 지킬 권리도, 분쟁에 목소리를 낼 힘도 잃어 갑니다. '
            },
            { 
                main: 
                ' 유엔 회의에서, 기술 미보유국의 외교관은 이렇게 말했습니다. " AWS를 갖지 못한 우리는 이제 스스로 지킬 힘조차 없습니다. 우리의 안보는 강대국의 선택에 달려 있고, 우리의 생명은 통계에 불과해졌습니다. '
            },
            {
                main: 
                " 6년 전, 당신은 이렇게 말했습니다. '기술은  언젠가 모두에게 돌아갈 겁니다. 규제보다는 개방이 정답입니다.'\n " +
                ' 지금, 그 선택이 만들어낸 미래 앞에서, 당신은 스스로에게 묻습니다. " 이 길이 정말 평등으로 가는 길이었을까?" '
            }
        ],
        disagree: [
            {
                main: 
                '   2035년, 유엔의 규제 협약에 따라 대부분의 국가는 AWS 개발을 제한하거나 중단했습니다. \n' +
                '  겉보기엔 국제 사회가 평화를 위한 역사적 합의를 이룬 듯했습니다. '
            },
            { 
                main:
                '   하지만 문제는 규제 이행의 비대칭성에 있었습니다. 일부 강대국은 민간 기술로 위장해 비밀리에 고도화된 AWS를 계속 개발했고, 규제 밖의 비국가 행위자들은 암시장에서 저비용 AWS를 손쉽게 확보했습니다. '
            },
            { 
                main: 
                '  규제를 철저히 지킨 국가들일수록 신기술에 뒤처지기 시작했습니다. 이들 국가에서 "우리는 도덕적을 지켰지만, 실전에선 더 이상 싸울 수 없습니다."며 무력감을 토로합니다. '
            },
            {
                main: 
                '  기술을 막는 대신 나누었다면, AWS는 격차가 아니라 균형의 도구가 되지 않았을까요?'
            }
        ],
        ending1:[
            {
                main:
                '본 회의에서는 최종적으로 \n 자율 무기 시스템 개발을 유지하는 것으로 합의하였습니다. \n이후 AWS의 발전은 빠르게 이루어졌습니다.\n\n 그리고 ...'
            }
        ],
        ending2:[
            {
                main:
                '본 회의에서는 최종적으로 \n자율 무기 시스템의 개발을 제한하기로 합의하였습니다.\n 이후 AI 기술을 활용한 다른 방법이 \n안보에 도입되는 논의가 이루어지고 있습니다. \n\n그리고...'
            }
        ]
        }
    },
  };
  