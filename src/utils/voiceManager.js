// ìŒì„± ì†¡ìˆ˜ì‹ , websocket, webRTC ì—°ê²° ëª¨ë‘ ë§ˆì¹œ ìƒíƒœ + ìŒì„± ìŠ¤íŠ¸ë¦¼ 1ê°œ , ìŒì„± ë…¹ìŒ ì¢…ë£Œì™€ ë§ˆì´í¬ êº¼ì§ ì™„ë£Œ 
import axiosInstance from '../api/axiosInstance';

class VoiceManager {
  constructor() {
    this.isConnected = false;
    this.isSpeaking = false;
    this.sessionId = null;
    this.mediaStream = null;  // ğŸš¨ WebRTCì—ì„œ ë°›ì€ ìŠ¤íŠ¸ë¦¼
    this.audioContext = null;
    this.analyser = null;
    this.animationFrame = null;
    this.speakingThreshold = 30;
    this.nickname = null;
    this.participantId = null;
    this.lastSpeakingState = false;
    this.micLevel = 0;
    this.isDebugMode = true;
    
    // ì—°ì† ë…¹ìŒ ê´€ë ¨
    this.mediaRecorder = null;
    this.isRecording = false;
    this.recordedChunks = [];
    this.recordingStartTime = null;
    this.recordingMimeType = null;
    this.isTerminating = false;
    this.sessionInitialized = false;
    this.micNode = null;
    
    // ğŸš¨ WebRTC ìŠ¤íŠ¸ë¦¼ ì‚¬ìš© ì—¬ë¶€ í”Œë˜ê·¸
    this.usingWebRTCStream = false;

    // WAV ë³€í™˜ì´ ì •ë§ í•„ìš”í•  ë•Œ(ì„œë²„ê°€ WAVë§Œ ë°›ëŠ” ê²½ìš°)ë¥¼ ëŒ€ë¹„í•œ íƒ€ê²Ÿ
    // â€» ì¥ì‹œê°„(30~90ë¶„) ë…¹ìŒì€ WAVê°€ ë§¤ìš° ì»¤ì§ˆ ìˆ˜ ìˆìœ¼ë‹ˆ, ê¸°ë³¸ ì—…ë¡œë“œëŠ” webm/opus(ì••ì¶•) ê¶Œì¥
    this.TARGET_WAV_SAMPLE_RATE = 16000;

    // ì¥ì‹œê°„ ë…¹ìŒ ì•ˆì •ì„±: 1ì´ˆ ë‹¨ìœ„ ì²­í¬(Blob)ê°€ ìˆ˜ì²œ ê°œ ìŒ“ì´ë©´ ê°ì²´ ì˜¤ë²„í—¤ë“œê°€ ì»¤ì§ˆ ìˆ˜ ìˆì–´
    // timesliceë¥¼ ëŠ˜ë ¤(ì˜ˆ: 10ì´ˆ) ì²­í¬ ê°œìˆ˜ë¥¼ ì¤„ì…ë‹ˆë‹¤.
    this.RECORDING_TIMESLICE_MS = 10000;
    // Opus ë¹„íŠ¸ë ˆì´íŠ¸(ë¸Œë¼ìš°ì €ê°€ ë¬´ì‹œí•  ìˆ˜ ìˆìŒ). ë„ˆë¬´ ë†’ì´ë©´ ì—…ë¡œë“œê°€ ì»¤ì§.
    this.AUDIO_BITS_PER_SECOND = 24000;
  }

  // ----------------------------
  // helpers: mime / wav encode
  // ----------------------------
  _pickSupportedMimeType(candidates) {
    try {
      if (typeof MediaRecorder === 'undefined') return null;
      if (typeof MediaRecorder.isTypeSupported !== 'function') return null;
      for (const t of candidates) {
        if (t && MediaRecorder.isTypeSupported(t)) return t;
      }
      return null;
    } catch {
      return null;
    }
  }

  async _readFirstAscii(blob, n = 4) {
    try {
      const ab = await blob.slice(0, n).arrayBuffer();
      const bytes = new Uint8Array(ab);
      let s = '';
      for (let i = 0; i < bytes.length; i++) s += String.fromCharCode(bytes[i]);
      return s;
    } catch {
      return '';
    }
  }

  async _ensureWavBlob(inputBlob) {
    // ì´ë¯¸ WAVì²˜ëŸ¼ ë³´ì´ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
    const head4 = await this._readFirstAscii(inputBlob, 4);
    if ((inputBlob.type || '').includes('wav') && head4 === 'RIFF') {
      return inputBlob;
    }

    // webm/ogg ë“± â†’ decode â†’ (downsample/mono) â†’ PCM â†’ WAV ì¸ì½”ë”©
    const arrayBuffer = await inputBlob.arrayBuffer();
    const AudioCtx = window.AudioContext || window.webkitAudioContext;
    if (!AudioCtx) throw new Error('AudioContext ë¯¸ì§€ì› í™˜ê²½');

    const ctx = new AudioCtx();
    try {
      const audioBuffer = await ctx.decodeAudioData(arrayBuffer.slice(0));
      const optimized = await this._downsampleToMono(audioBuffer, this.TARGET_WAV_SAMPLE_RATE);
      const wavAb = this._encodeWavFromAudioBuffer(optimized);
      const wavBlob = new Blob([wavAb], { type: 'audio/wav' });

      const wavHead = await this._readFirstAscii(wavBlob, 4);
      if (wavHead !== 'RIFF') {
        throw new Error(`WAV ë³€í™˜ ì‹¤íŒ¨(í—¤ë” ë¶ˆì¼ì¹˜): head=${JSON.stringify(wavHead)}`);
      }

      return wavBlob;
    } finally {
      try { await ctx.close(); } catch {}
    }
  }

  async _downsampleToMono(audioBuffer, targetSampleRate = 16000) {
    try {
      if (!audioBuffer) return audioBuffer;
      const srcRate = audioBuffer.sampleRate || targetSampleRate;
      const duration = audioBuffer.duration || (audioBuffer.length / (srcRate || 1));

      // ì´ë¯¸ target rate + monoë©´ ê·¸ëŒ€ë¡œ
      if ((audioBuffer.numberOfChannels || 1) === 1 && srcRate === targetSampleRate) {
        return audioBuffer;
      }

      const OfflineCtx = window.OfflineAudioContext || window.webkitOfflineAudioContext;
      if (!OfflineCtx) return audioBuffer;

      const length = Math.max(1, Math.ceil(duration * targetSampleRate));
      const offline = new OfflineCtx(1, length, targetSampleRate);

      const source = offline.createBufferSource();
      source.buffer = audioBuffer;
      source.connect(offline.destination); // mono destinationìœ¼ë¡œ ìë™ downmix
      source.start(0);

      const rendered = await offline.startRendering();
      return rendered || audioBuffer;
    } catch (e) {
      console.warn('âš ï¸ downsample/mono ìµœì í™” ì‹¤íŒ¨ â†’ ì›ë³¸ ìƒ˜í”Œë ˆì´íŠ¸ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.', e);
      return audioBuffer;
    }
  }

  _encodeWavFromAudioBuffer(audioBuffer) {
    const numChannels = audioBuffer.numberOfChannels || 1;
    const sampleRate = audioBuffer.sampleRate || 44100;
    const format = 1; // PCM
    const bitsPerSample = 16;

    const samples = audioBuffer.length;
    const blockAlign = numChannels * (bitsPerSample / 8);
    const byteRate = sampleRate * blockAlign;
    const dataSize = samples * blockAlign;

    const buffer = new ArrayBuffer(44 + dataSize);
    const view = new DataView(buffer);

    const writeString = (offset, str) => {
      for (let i = 0; i < str.length; i++) view.setUint8(offset + i, str.charCodeAt(i));
    };

    let offset = 0;
    writeString(offset, 'RIFF'); offset += 4;
    view.setUint32(offset, 36 + dataSize, true); offset += 4;
    writeString(offset, 'WAVE'); offset += 4;
    writeString(offset, 'fmt '); offset += 4;
    view.setUint32(offset, 16, true); offset += 4;              // Subchunk1Size
    view.setUint16(offset, format, true); offset += 2;           // AudioFormat
    view.setUint16(offset, numChannels, true); offset += 2;      // NumChannels
    view.setUint32(offset, sampleRate, true); offset += 4;       // SampleRate
    view.setUint32(offset, byteRate, true); offset += 4;         // ByteRate
    view.setUint16(offset, blockAlign, true); offset += 2;       // BlockAlign
    view.setUint16(offset, bitsPerSample, true); offset += 2;    // BitsPerSample
    writeString(offset, 'data'); offset += 4;
    view.setUint32(offset, dataSize, true); offset += 4;

    // interleave + float(-1..1) â†’ int16
    const channels = [];
    for (let ch = 0; ch < numChannels; ch++) channels.push(audioBuffer.getChannelData(ch));

    let dataOffset = 44;
    for (let i = 0; i < samples; i++) {
      for (let ch = 0; ch < numChannels; ch++) {
        let s = channels[ch][i];
        s = Math.max(-1, Math.min(1, s));
        view.setInt16(dataOffset, s < 0 ? s * 0x8000 : s * 0x7fff, true);
        dataOffset += 2;
      }
    }

    return buffer;
  }

  // async uploadRecordingToServer(recordingData) {
  //   try {
  //     if (!recordingData?.blob || !recordingData.blob.size) {
  //       console.warn('âš ï¸ ì—…ë¡œë“œí•  ë…¹ìŒ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.');
  //       return null;
  //     }
      
  //     const sessId = this.sessionId || localStorage.getItem('session_id');
  //     if (!sessId) {
  //       console.error('âŒ uploadRecordingToServer: session_idê°€ ì—†ìŠµë‹ˆë‹¤.');
  //       return null;
  //     }

  //     const ts = new Date().toISOString().replace(/[:.]/g, '-');
  //     const filename = `recording_${sessId}_${ts}.webm`;
  //     const file = new File([recordingData.blob], filename, { type: 'audio/webm' });

  //     const form = new FormData();
  //     form.append('file', file);
  //     const url = `/upload_audio`;

  //     const { data } = await axiosInstance.post(url, form, {
  //       maxBodyLength: Infinity,
  //     });

  //     console.log('âœ… ì—…ë¡œë“œ ì„±ê³µ:', data);
  //     return data;
  //   } catch (error) {
  //     console.error('âŒ ì—…ë¡œë“œ ì‹¤íŒ¨:', {
  //       status: error.response?.status,
  //       data: error.response?.data,
  //       message: error.message,
  //     });
  //     return null;
  //   }
  // }
  async uploadRecordingToServer(recordingData) {
    try {
      if (!recordingData?.blob || !recordingData.blob.size) {
        console.warn('âš ï¸ ì—…ë¡œë“œí•  ë…¹ìŒ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.');
        return null;
      }
  
      const sessId = this.sessionId || localStorage.getItem('session_id');
      if (!sessId) {
        console.error('âŒ uploadRecordingToServer: session_idê°€ ì—†ìŠµë‹ˆë‹¤.');
        return null;
      }
  
      // âœ… ì¥ì‹œê°„(30~90ë¶„) ë…¹ìŒì€ WAV ë³€í™˜ ì‹œ ìš©ëŸ‰ì´ í­ì¦(413 ìœ„í—˜)í•˜ë¯€ë¡œ,
      // ê¸°ë³¸ì€ MediaRecorder ì›ë³¸(webm/ogg + opus)ì„ ê·¸ëŒ€ë¡œ ì—…ë¡œë“œí•©ë‹ˆë‹¤.
      // (ì„œë²„ê°€ WAVë§Œ ë°›ëŠ”ë‹¤ë©´: ì„œë²„ì—ì„œ ë³€í™˜í•˜ê±°ë‚˜, ì •ë§ í•„ìš”í•  ë•Œë§Œ _ensureWavBlobë¥¼ ì‚¬ìš©)
      const sourceBlob = recordingData.blob;
      const ts = new Date().toISOString().replace(/[:.]/g, '-');
      const uid = this.participantId || localStorage.getItem('user_id') || 'unknown';

      const mime = sourceBlob.type || 'audio/webm';
      const ext =
        mime.includes('ogg') ? 'ogg' :
        mime.includes('webm') ? 'webm' :
        mime.includes('wav') ? 'wav' :
        'webm';

      const file = new File([sourceBlob], `recording_${uid}_${ts}.${ext}`, { type: mime });
  
      const form = new FormData();
      form.append('session_id', sessId); 
      form.append('file', file);         
  
      // Content-Type ìë™ (multipart/form-data; boundary=...)
      const { data } = await axiosInstance.postForm('/upload_audio', form);

  
      console.log('âœ… ì—…ë¡œë“œ ì„±ê³µ:', {
        session_id: sessId,
        user_id: uid,
        fileSize: file.size,
        durationMs: recordingData?.duration,
        chunks: recordingData?.chunks,
        sourceType: sourceBlob.type,
        uploadType: file.type,
        server: data
      });
      return data;
    } catch (error) {
      console.error('âŒ ì—…ë¡œë“œ ì‹¤íŒ¨:', {
        status: error.response?.status,
        data: error.response?.data,
        message: error.message,
      });
      return null;
    }
  }
  

  async leaveSession() {
    this.sessionId ||= localStorage.getItem('session_id');
    
    if (!this.sessionId) {
      console.warn('âš ï¸ leaveSession: sessionIdê°€ ì—†ìŠµë‹ˆë‹¤.');
      return false;
    }
    
    try {
      await axiosInstance.post(`/voice/sessions/${this.sessionId}/leave`, {});
      console.log('âœ… leaveSession ì„±ê³µ');
      return true;
    } catch (err) {
      console.error('âŒ leaveSession ì‹¤íŒ¨:', err);
      return false;
    }
  }

  getLocalStream() {
    return this.mediaStream;
  }
  
  getAudioTracks() {
    return this.mediaStream ? this.mediaStream.getAudioTracks() : [];
  }

  // ğŸš¨ í•µì‹¬ ìˆ˜ì •: WebRTC ìŠ¤íŠ¸ë¦¼ì„ ë°›ëŠ” ì´ˆê¸°í™” í•¨ìˆ˜
  async initializeVoiceSession(webRTCMediaStream = null) {
    if (this.sessionInitialized) {
      console.log('âš ï¸ ìŒì„± ì„¸ì…˜ì´ ì´ë¯¸ ì´ˆê¸°í™”ë˜ì–´ ìˆìŒ');
      return true;
    }
  
    try {
      console.log('ğŸ¤ VoiceManager ì´ˆê¸°í™” ì‹œì‘');
      
      // 1. ì„¸ì…˜ ì •ë³´ í™•ì¸
      this.sessionId = localStorage.getItem('session_id');
      if (!this.sessionId) {
        console.error('âŒ session_idê°€ ì—†ìŠµë‹ˆë‹¤.');
        return false;
      }
      
      if (typeof this.sessionId !== 'string' || this.sessionId.length === 0) {
        console.error('âŒ ìœ íš¨í•˜ì§€ ì•Šì€ session_id í˜•ì‹:', this.sessionId);
        return false;
      }
      
      // 2. ë°±ì—”ë“œ ì„¸ì…˜ ìœ íš¨ì„± í™•ì¸
      try {
        const sessionVerify = await axiosInstance.get(`/voice/sessions/${this.sessionId}`);
        console.log('âœ… VoiceManager: ì„¸ì…˜ ìœ íš¨ì„± í™•ì¸ë¨:', sessionVerify.data);
      } catch (verifyError) {
        console.error('âŒ VoiceManager: ì„¸ì…˜ ìœ íš¨ì„± í™•ì¸ ì‹¤íŒ¨:', verifyError.response?.data);
        return false;
      }
      
      // 3. ì‚¬ìš©ì ì •ë³´ ì„¤ì •
      // âœ… ê²ŒìŠ¤íŠ¸ì˜ /users/meê°€ 500ì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ localStorage ìš°ì„  ì‚¬ìš©
      const storedUserId = localStorage.getItem('user_id');
      const storedNickname = localStorage.getItem('nickname');
      if (storedUserId) this.participantId = String(storedUserId);
      if (storedNickname) this.nickname = String(storedNickname);

      // fallback: ë¡œì»¬ì— ì—†ì„ ë•Œë§Œ /users/me ì‹œë„ (íšŒì›/ë ˆê±°ì‹œ ëŒ€ì‘)
      if (!this.participantId || !this.nickname) {
        try {
          const { data: userInfo } = await axiosInstance.get('/users/me');
          if (!this.participantId && userInfo?.id != null) this.participantId = String(userInfo.id);
          if (!this.nickname) this.nickname = userInfo?.username || (this.participantId ? `Player_${this.participantId}` : null);
        } catch (e) {
          // ê²ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ì—ì„œ í”íˆ ë°œìƒ: ìµœì†Œê°’ìœ¼ë¡œ ì§„í–‰
          if (!this.participantId) this.participantId = storedUserId ? String(storedUserId) : 'unknown';
          if (!this.nickname) this.nickname = storedNickname ? String(storedNickname) : (this.participantId ? `Player_${this.participantId}` : 'Player');
          console.warn('âš ï¸ VoiceManager: /users/me ì¡°íšŒ ì‹¤íŒ¨. localStorage ê¸°ë°˜ìœ¼ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.', e?.response?.data || e?.message);
        }
      }
      
      console.log('ğŸ“‹ VoiceManager ì„¸ì…˜ ì •ë³´:', {
        sessionId: this.sessionId,
        nickname: this.nickname,
        participantId: this.participantId,
        hasWebRTCStream: !!webRTCMediaStream
      });
      
      // ğŸš¨ 4. í•µì‹¬: WebRTC ìŠ¤íŠ¸ë¦¼ ì‚¬ìš©
      if (webRTCMediaStream) {
        console.log('âœ… WebRTC ìŠ¤íŠ¸ë¦¼ ì‚¬ìš©:', webRTCMediaStream.id);
        this.mediaStream = webRTCMediaStream;
        this.usingWebRTCStream = true;
        this.isConnected = true;
        
        // WebRTC ìŠ¤íŠ¸ë¦¼ìœ¼ë¡œ ì˜¤ë””ì˜¤ ë¶„ì„ ì„¤ì •
        await this.setupAudioAnalysisWithWebRTCStream(webRTCMediaStream);
      } else {
        console.error('âŒ WebRTC ìŠ¤íŠ¸ë¦¼ì´ ì „ë‹¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤');
        return false;
      }
      
      // 5. ì´ˆê¸° ë§ˆì´í¬ ON ìƒíƒœ ì „ì†¡
      await this.sendVoiceStatusToServer(false);
      
      // 6. ìŒì„± ê°ì§€ ì‹œì‘
      this.startSpeechDetection();
      
      // 7. ì—°ì† ë…¹ìŒ ì‹œì‘
      this.startRecording();
      
      this.sessionInitialized = true;
      console.log('âœ… VoiceManager ì´ˆê¸°í™” ì™„ë£Œ (WebRTC ìŠ¤íŠ¸ë¦¼ ì‚¬ìš©)');
      return true;
      
    } catch (error) {
      console.error('âŒ VoiceManager ì´ˆê¸°í™” ì‹¤íŒ¨:', error);
      console.error('âŒ ì—ëŸ¬ ìƒì„¸:', {
        message: error.message,
        response: error.response?.data,
        status: error.response?.status
      });
      return false;
    }
  }

  // ğŸš¨ WebRTC ìŠ¤íŠ¸ë¦¼ìœ¼ë¡œ ì˜¤ë””ì˜¤ ë¶„ì„ ì„¤ì •
  async setupAudioAnalysisWithWebRTCStream(webRTCStream) {
    try {
      console.log('ğŸ”Š WebRTC ìŠ¤íŠ¸ë¦¼ìœ¼ë¡œ ì˜¤ë””ì˜¤ ë¶„ì„ ì„¤ì • ì¤‘...');
      
      this.audioContext = new (window.AudioContext || window.webkitAudioContext)();
      this.analyser = this.audioContext.createAnalyser();
      
      // ğŸš¨ ì¤‘ìš”: WebRTC ìŠ¤íŠ¸ë¦¼ì„ AudioContextì— ì—°ê²° (ë¶„ì„ìš©)
      this.micNode = this.audioContext.createMediaStreamSource(webRTCStream);
      this.micNode.connect(this.analyser);
      
      this.analyser.fftSize = 256;
      this.analyser.smoothingTimeConstant = 0.8;
      
      console.log('âœ… WebRTC ìŠ¤íŠ¸ë¦¼ ì˜¤ë””ì˜¤ ë¶„ì„ ì„¤ì • ì™„ë£Œ');
      
    } catch (error) {
      console.error('âŒ WebRTC ìŠ¤íŠ¸ë¦¼ ì˜¤ë””ì˜¤ ë¶„ì„ ì„¤ì • ì‹¤íŒ¨:', error);
      throw error;
    }
  }

  // ì—°ì† ë…¹ìŒ ì‹œì‘
  startRecording() {
    if (!this.mediaStream || this.isRecording) return;

    try {
      // ê°€ëŠ¥í•œ ê²½ìš° WAVë¡œ ì§ì ‘ ë…¹ìŒ(ë¸Œë¼ìš°ì € ì§€ì› ì‹œ), ì•„ë‹ˆë©´ webm/oggë¡œ ë…¹ìŒ í›„ ì—…ë¡œë“œ ë•Œ WAVë¡œ ë³€í™˜
      const preferred = this._pickSupportedMimeType([
        'audio/webm;codecs=opus',
        'audio/webm',
        'audio/ogg;codecs=opus',
        'audio/ogg',
        // WAV ì§ì ‘ ë…¹ìŒì€ íŒŒì¼ì´ ì»¤ì§€ê¸° ì‰¬ì›Œ ë§ˆì§€ë§‰ fallbackìœ¼ë¡œ ë‘ 
        'audio/wav',
        'audio/wav;codecs=1',
      ]);

      this.recordingMimeType = preferred || null;

      const mrOptions = {};
      if (preferred) mrOptions.mimeType = preferred;
      // ë¸Œë¼ìš°ì € ì§€ì› ì‹œì—ë§Œ ì ìš©ë¨(ë¬´ì‹œë  ìˆ˜ ìˆìŒ)
      mrOptions.audioBitsPerSecond = this.AUDIO_BITS_PER_SECOND;

      this.mediaRecorder = new MediaRecorder(this.mediaStream, mrOptions);

      this.recordedChunks = [];
      this.recordingStartTime = Date.now();

      this.mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          this.recordedChunks.push(event.data);
        }
      };

      this.mediaRecorder.onstop = () => {
        console.log('ğŸµ ë…¹ìŒ ì¢…ë£Œ, ì´ ì²­í¬:', this.recordedChunks.length);
      };

      this.mediaRecorder.start(this.RECORDING_TIMESLICE_MS);
      this.isRecording = true;
      
      console.log('ğŸ”´ ì—°ì† ë…¹ìŒ ì‹œì‘ (WebRTC ìŠ¤íŠ¸ë¦¼ ì‚¬ìš©)', {
        mimeType: this.recordingMimeType || this.mediaRecorder?.mimeType || 'unknown',
        startTime: new Date(this.recordingStartTime).toISOString(),
        timesliceMs: this.RECORDING_TIMESLICE_MS,
        audioBitsPerSecond: this.AUDIO_BITS_PER_SECOND
      });
    } catch (error) {
      console.error('âŒ ë…¹ìŒ ì‹œì‘ ì‹¤íŒ¨:', error);
    }
  }

  // ì„œë²„ì— ìŒì„± ìƒíƒœ ì „ì†¡
  async sendVoiceStatusToServer(isSpeaking) {
    try {
      if (!this.participantId || this.participantId === 'unknown' || Number.isNaN(parseInt(this.participantId))) {
        console.warn('âš ï¸ sendVoiceStatusToServer: participantIdê°€ ìœ íš¨í•˜ì§€ ì•Šì•„ ì „ì†¡ì„ ê±´ë„ˆëœë‹ˆë‹¤.', this.participantId);
        return;
      }
      if (this.lastSpeakingState === isSpeaking) return;
      this.lastSpeakingState = isSpeaking;

      const message = {
        type: "voice_status_update",
        data:{
            user_id: parseInt(this.participantId),
            is_mic_on: this.isConnected,
            is_speaking: isSpeaking,
            session_id: this.sessionId
        }
      };

       if (window.webSocketInstance && window.webSocketInstance.sendMessage) {
        const success = window.webSocketInstance.sendMessage(message);
          if (success) {
          console.log('ğŸ“¡ WebSocketìœ¼ë¡œ ìŒì„± ìƒíƒœ ì „ì†¡:', message);
        }
      } else {
        console.warn('âš ï¸ WebSocket ì¸ìŠ¤í„´ìŠ¤ê°€ ì—†ìŒ');
      }
      
    } catch (error) {
      console.error('ìŒì„± ìƒíƒœ ì „ì†¡ ì‹¤íŒ¨:', error);
      this.lastSpeakingState = !isSpeaking;
    }
  }

  // ìŒì„± ê°ì§€ ì‹œì‘
  startSpeechDetection() {
    if (!this.analyser) {
      console.error('âŒ ë¶„ì„ê¸°ê°€ ì—†ìŠµë‹ˆë‹¤');
      return;
    }

    const bufferLength = this.analyser.frequencyBinCount;
    const dataArray = new Uint8Array(bufferLength);
    
    const detectSpeech = () => {
      if (!this.analyser) return;
      
      this.analyser.getByteFrequencyData(dataArray);
      
      const average = dataArray.reduce((sum, value) => sum + value, 0) / bufferLength;
      this.micLevel = average;
      
      const currentlySpeaking = average > this.speakingThreshold;
      
      if (currentlySpeaking !== this.isSpeaking) {
        this.isSpeaking = currentlySpeaking;
      }
      
      this.animationFrame = requestAnimationFrame(detectSpeech);
    };
    
    console.log('ğŸ‘‚ ìŒì„± ê°ì§€ ì‹œì‘ (WebRTC ìŠ¤íŠ¸ë¦¼) (ì„ê³„ê°’:', this.speakingThreshold, ')');
    detectSpeech();
  }

  // ì„ê³„ê°’ ì¡°ì •
  setSpeakingThreshold(threshold) {
    this.speakingThreshold = threshold;
    console.log('ğŸ”§ ìŒì„± ì„ê³„ê°’ ë³€ê²½:', threshold);
  }

  // ë””ë²„ê·¸ ëª¨ë“œ í† ê¸€
  toggleDebugMode() {
    this.isDebugMode = !this.isDebugMode;
    console.log('ğŸ› ë””ë²„ê·¸ ëª¨ë“œ:', this.isDebugMode ? 'ON' : 'OFF');
  }

  // ìŒì„± ê°ì§€ ì¤‘ì§€
  stopSpeechDetection() {
    if (this.animationFrame) {
      cancelAnimationFrame(this.animationFrame);
      this.animationFrame = null;
    }
    console.log('â¹ï¸ ìŒì„± ê°ì§€ ì¤‘ì§€');
  }

  // ìˆ˜ì •ëœ stopRecording ë©”ì„œë“œ
  async stopRecording() {
    console.log('ğŸµ stopRecording ì‹œì‘ - ìƒíƒœ í™•ì¸:', {
      mediaRecorder: !!this.mediaRecorder,
      mediaRecorderState: this.mediaRecorder?.state,
      isRecording: this.isRecording,
      chunksLength: this.recordedChunks?.length || 0,
      usingWebRTCStream: this.usingWebRTCStream
    });

    if (!this.mediaRecorder) {
      console.warn('âš ï¸ stopRecording: mediaRecorderê°€ ì—†ìŒ');
      
      if (this.recordedChunks?.length > 0) {
        console.log('ğŸ“¦ ê¸°ì¡´ ì²­í¬ë¡œ Blob ìƒì„±:', this.recordedChunks.length);
        const type = this.recordingMimeType || this.recordedChunks?.[0]?.type || 'audio/webm';
        const blob = new Blob(this.recordedChunks, { type });
        const duration = this.recordingStartTime ? (Date.now() - this.recordingStartTime) : 0;
        const chunks = this.recordedChunks?.length || 0;
        
        this.isRecording = false;
        this.recordedChunks = [];
        this.recordingMimeType = null;
        
        return {
          blob,
          duration,
          chunks,
          startTime: this.recordingStartTime,
          endTime: Date.now()
        };
      }
      
      this.isRecording = false;
      this.recordingMimeType = null;
      return null;
    }

    if (this.mediaRecorder.state === 'inactive') {
      console.log('ğŸ“ MediaRecorderê°€ ì´ë¯¸ inactive ìƒíƒœ');
      
      if (this.recordedChunks?.length > 0) {
        const type = this.recordingMimeType || this.recordedChunks?.[0]?.type || 'audio/webm';
        const blob = new Blob(this.recordedChunks, { type });
        const duration = this.recordingStartTime ? (Date.now() - this.recordingStartTime) : 0;
        const chunks = this.recordedChunks?.length || 0;
        
        console.log('ğŸ“¦ inactive ìƒíƒœì—ì„œ Blob ìƒì„±:', {
          size: blob.size,
          duration,
          chunks
        });
        
        this.isRecording = false;
        this.recordedChunks = [];
        this.recordingMimeType = null;
        
        return {
          blob,
          duration,
          chunks,
          startTime: this.recordingStartTime,
          endTime: Date.now()
        };
      }
      
      this.isRecording = false;
      this.recordingMimeType = null;
      return null;
    }

    return new Promise((resolve) => {
      let resolved = false;
      
      const finalize = () => {
        if (resolved) return;
        resolved = true;
        
        try {
          const type = this.recordingMimeType || this.recordedChunks?.[0]?.type || 'audio/webm';
          const blob = new Blob(this.recordedChunks || [], { type });
          const duration = this.recordingStartTime ? (Date.now() - this.recordingStartTime) : 0;
          const chunks = this.recordedChunks?.length || 0;
          
          console.log('â¹ï¸ ë…¹ìŒ ì™„ë£Œ:', {
            size: blob.size,
            duration,
            chunks
          });
          
          this.isRecording = false;
          this.recordedChunks = [];
          this.mediaRecorder = null;
          this.recordingMimeType = null;
          
          resolve({
            blob,
            duration,
            chunks,
            startTime: this.recordingStartTime,
            endTime: Date.now()
          });
        } catch (error) {
          console.error('âŒ finalize ì¤‘ ì˜¤ë¥˜:', error);
          this.isRecording = false;
          this.recordedChunks = [];
          this.mediaRecorder = null;
          this.recordingMimeType = null;
          resolve(null);
        }
      };

      this.mediaRecorder.onstop = () => {
        console.log('ğŸ“ MediaRecorder onstop ì´ë²¤íŠ¸ ë°œìƒ');
        try {
          finalize();
        } catch (e) {
          console.error('âŒ onstop í•¸ë“¤ëŸ¬ ì˜¤ë¥˜:', e);
          resolved = true;
          resolve(null);
        }
      };

      this.mediaRecorder.onerror = (event) => {
        console.error('âŒ MediaRecorder ì˜¤ë¥˜:', event.error);
        if (!resolved) {
          resolved = true;
          this.isRecording = false;
          this.recordedChunks = [];
          this.mediaRecorder = null;
          this.recordingMimeType = null;
          resolve(null);
        }
      };

      try {
        if (typeof this.mediaRecorder.requestData === 'function') {
          console.log('ğŸ“¤ ë§ˆì§€ë§‰ ë°ì´í„° ìš”ì²­');
          this.mediaRecorder.requestData();
        }
      } catch (e) {
        console.warn('âš ï¸ requestData ì‹¤íŒ¨ (ë¬´ì‹œ):', e.message);
      }

      try {
        console.log('ğŸ›‘ MediaRecorder.stop() í˜¸ì¶œ');
        this.mediaRecorder.stop();
        this.isRecording = false;
      } catch (e) {
        console.error('âŒ MediaRecorder.stop() ì˜¤ë¥˜:', e);
        finalize();
        return;
      }

      setTimeout(() => {
        if (!resolved) {
          console.warn('â±ï¸ onstop ì´ë²¤íŠ¸ íƒ€ì„ì•„ì›ƒ - ê°•ì œ ì™„ë£Œ');
          finalize();
        }
      }, 3000);
    });
  }

  // // ğŸš¨ ìˆ˜ì •ëœ disconnectMicrophone - WebRTC ìŠ¤íŠ¸ë¦¼ì€ ê±´ë“œë¦¬ì§€ ì•ŠìŒ
  // disconnectMicrophone() {
  //   console.log('ğŸ”‡ ë§ˆì´í¬ ì—°ê²° í•´ì œ ì‹œì‘ (WebRTC ìŠ¤íŠ¸ë¦¼ ë³´ì¡´)');
    
  //   // 1. ìŒì„± ê°ì§€ ì¤‘ì§€
  //   this.stopSpeechDetection();
    
  //   // 2. ì˜¤ë””ì˜¤ ë…¸ë“œ ì—°ê²° í•´ì œ
  //   try {
  //     if (this.micNode) {
  //       this.micNode.disconnect();
  //       this.micNode = null;
  //       console.log('ğŸ”Œ ì˜¤ë””ì˜¤ ë…¸ë“œ ì—°ê²° í•´ì œ ì™„ë£Œ');
  //     }
  //   } catch (e) {
  //     console.warn('âš ï¸ ì˜¤ë””ì˜¤ ë…¸ë“œ í•´ì œ ì‹¤íŒ¨:', e);
  //   }

  //   // ğŸš¨ 3. WebRTC ìŠ¤íŠ¸ë¦¼ì€ ì •ì§€í•˜ì§€ ì•ŠìŒ (WebRTCì—ì„œ ê´€ë¦¬)
  //   console.log('âš ï¸ WebRTC ìŠ¤íŠ¸ë¦¼ì€ WebRTC Providerì—ì„œ ê´€ë¦¬í•˜ë¯€ë¡œ ì—¬ê¸°ì„œ ì •ì§€í•˜ì§€ ì•ŠìŒ');
    
  //   // 4. AudioContext ì •ë¦¬
  //   if (this.audioContext) {
  //     try {
  //       if (this.audioContext.state !== 'closed') {
  //         this.audioContext.close();
  //         console.log('ğŸ”Š AudioContext ì¢…ë£Œ ì™„ë£Œ');
  //       }
  //     } catch (e) {
  //       console.warn('âš ï¸ AudioContext ì¢…ë£Œ ì‹¤íŒ¨:', e);
  //     }
  //     this.audioContext = null;
  //   }
    
  //   // 5. ìƒíƒœ ì´ˆê¸°í™” (ìŠ¤íŠ¸ë¦¼ ì°¸ì¡°ëŠ” ìœ ì§€)
  //   this.analyser = null;
  //   this.isConnected = false;
  //   this.isSpeaking = false;
  //   this.lastSpeakingState = false;
  //   this.micLevel = 0;
    
  //   console.log('âœ… VoiceManager ì •ë¦¬ ì™„ë£Œ (WebRTC ìŠ¤íŠ¸ë¦¼ ë³´ì¡´)');
  // }

  // VoiceManager.js - disconnectMicrophone í•¨ìˆ˜ ìˆ˜ì •
disconnectMicrophone() {
  console.log('ğŸ”‡ ë§ˆì´í¬ ì—°ê²° í•´ì œ ì‹œì‘');
  
  // 1. ìŒì„± ê°ì§€ ì¤‘ì§€
  this.stopSpeechDetection();
  
  // 2. ì˜¤ë””ì˜¤ ë…¸ë“œ ì—°ê²° í•´ì œ
  try {
    if (this.micNode) {
      this.micNode.disconnect();
      this.micNode = null;
      console.log('ğŸ”Œ ì˜¤ë””ì˜¤ ë…¸ë“œ ì—°ê²° í•´ì œ ì™„ë£Œ');
    }
  } catch (e) {
    console.warn('âš ï¸ ì˜¤ë””ì˜¤ ë…¸ë“œ í•´ì œ ì‹¤íŒ¨:', e);
  }

  // ğŸš¨ 3. í•µì‹¬ ìˆ˜ì •: ìŠ¤íŠ¸ë¦¼ ì°¸ì¡° ì™„ì „ ì œê±°
  console.log('ğŸ”‡ ìŠ¤íŠ¸ë¦¼ ì°¸ì¡° ì™„ì „ ì œê±°');
  this.mediaStream = null; // ğŸ¯ ì´ ì¤„ ì¶”ê°€!
  
  // 4. AudioContext ì •ë¦¬
  if (this.audioContext) {
    try {
      if (this.audioContext.state !== 'closed') {
        this.audioContext.close();
        console.log('ğŸ”Š AudioContext ì¢…ë£Œ ì™„ë£Œ');
      }
    } catch (e) {
      console.warn('âš ï¸ AudioContext ì¢…ë£Œ ì‹¤íŒ¨:', e);
    }
    this.audioContext = null;
  }
  
  // 5. ìƒíƒœ ì´ˆê¸°í™”
  this.analyser = null;
  this.isConnected = false;
  this.isSpeaking = false;
  this.lastSpeakingState = false;
  this.micLevel = 0;
  
  console.log('âœ… VoiceManager ì •ë¦¬ ì™„ë£Œ (ìŠ¤íŠ¸ë¦¼ ì°¸ì¡°ê¹Œì§€ ì œê±°)');
}
// VoiceManager.js - terminateVoiceSession ì˜¬ë°”ë¥¸ ìˆœì„œë¡œ ìˆ˜ì •

async terminateVoiceSession() {
  if (this.isTerminating) {
    console.warn('âš ï¸ terminateVoiceSession: ì´ë¯¸ ì¢…ë£Œ ì²˜ë¦¬ ì¤‘ (ì¤‘ë³µ í˜¸ì¶œ ë°©ì§€)');
    return null;
  }

  this.isTerminating = true;
  console.log('ğŸ›‘ ìŒì„± ì„¸ì…˜ ì™„ì „ ì¢…ë£Œ ì‹œì‘');

  try {
    // ğŸš¨ WebRTC ì „ì—­ í•¨ìˆ˜ í˜¸ì¶œ (í•œ ì¤„ë¡œ ë!)
    if (window.terminateWebRTCSession) {
      console.log('âœ… WebRTC ì „ì—­ í•¨ìˆ˜ í˜¸ì¶œ ì¤‘...');
      const result = await window.terminateWebRTCSession();
      console.log('âœ… WebRTC ì™„ì „ ì •ë¦¬ ì™„ë£Œ');
      return result;
    }

    console.error('âŒ window.terminateWebRTCSession í•¨ìˆ˜ê°€ ì—†ìŒ');

    // ğŸš¨ ë°±ì—…: ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ ê°œë³„ ì²˜ë¦¬ (â€» ì—…ë¡œë“œëŠ” Provider ìª½ì—ì„œ í•˜ëŠ” êµ¬ì¡°ë¼ ì—¬ê¸°ì„  stop+ì •ë¦¬ë§Œ)
    const recordingData = await this.stopRecording();
    this.disconnectMicrophone();

    if (window.stopAllOutgoingAudioGlobal) {
      window.stopAllOutgoingAudioGlobal();
    }

    return { recordingData, uploadResult: null };
  } catch (error) {
    console.error('âŒ ìŒì„± ì„¸ì…˜ ì¢…ë£Œ ì¤‘ ì˜¤ë¥˜:', error);
    return null;
  } finally {
    this.isTerminating = false;
  }
}

  // ì¼ì‹œì  ì •ë¦¬
  async cleanup() {
    if (this.isSpeaking) {
      await this.sendVoiceStatusToServer(false);
    }
  
    console.log('ğŸ§¹ ìŒì„± ì„¸ì…˜ ì¼ì‹œì  ì •ë¦¬ ì™„ë£Œ (ë…¹ìŒ ìœ ì§€)');
  }

  // í˜„ì¬ ìƒíƒœ ë°˜í™˜
  getStatus() {
    return {
      isConnected: this.isConnected,
      isSpeaking: this.isSpeaking,
      sessionId: this.sessionId,
      nickname: this.nickname,
      participantId: this.participantId,
      micLevel: this.micLevel,
      speakingThreshold: this.speakingThreshold,
      isRecording: this.isRecording,
      sessionInitialized: this.sessionInitialized,
      usingWebRTCStream: this.usingWebRTCStream  // ğŸš¨ ìƒˆë¡œ ì¶”ê°€
    };
  }
}

// ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
const voiceManager = new VoiceManager();

// ì „ì—­ì—ì„œ ì ‘ê·¼ ê°€ëŠ¥í•˜ë„ë¡ ì„¤ì •
window.voiceManager = voiceManager;

export default voiceManager;